---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

æ›¾å¾·ç‚‰ï¼Œåšå£«ï¼Œæ•™æˆï¼Œåšå£«ç”Ÿå¯¼å¸ˆ/ç¡•å£«ç”Ÿå¯¼å¸ˆã€‚æ›¾åœ¨ç›¸å…³é¢†åŸŸå‘è¡¨è®ºæ–‡100ä½™ç¯‡ï¼ŒåŒ…æ‹¬IEEEç­‰è‘—åä¼šåˆŠï¼Œå¦‚IEEE Trans. Neural Networks and Learning Systems, IEEE Trans. Image Processing, IEEE Geoscience and Remote Sensing Letters, IEEE Signal Processing Letters ï¼ŒåŠICMLï¼ŒAAAIï¼ŒIJCAIï¼ŒICCVï¼ŒCVPRï¼ŒICASSPç­‰è§†é¢‘å¤„ç†æ¨¡å¼è¯†åˆ«é¡¶çº§ä¼šè®®ã€‚ä¸»æŒå›½å®¶åŠçœéƒ¨çº§é¡¹ç›®å¤šé¡¹ï¼šåŒ…æ‹¬å›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘é¡¹ç›®3é¡¹ï¼Œä¸­å›½åšå£«ååŸºé‡‘é¡¹ç›®ç­‰ï¼›å‚ä¸å›½å®¶åŠçœéƒ¨çº§é¡¹ç›®å¤šé¡¹ç­‰ï¼›ä¸»æŒæ¨ªå‘é¡¹ç›®å¤šé¡¹ã€‚

å­¦æœ¯ä¹‰åŠ¡å·¥ä½œï¼šACMä¼šå‘˜ï¼ŒCCFä¼šå‘˜ï¼ŒIEEEä¼šå‘˜ï¼Œå‚ä¸NSFCè¯„å®¡ç­‰ï¼›å¹¶å‚ä¸å¤šä¸ªå›½é™…æœŸåˆŠå®¡ç¨¿ï¼ŒåŒ…æ‹¬IEEE TIPï¼ŒIEEE ITSï¼ŒIEEE TNNLSï¼ŒIEEE TIIï¼Œ IEEE TEIï¼ŒIEEE TMMï¼ŒIEEE SMCbï¼ŒNeural Networksï¼ŒNeurocomputingç­‰ã€‚


# ğŸ”¥ News
- *2026.1*: Our paper about *Diffusion Bridge Variational Inference for Deep Gaussian Processes* is accepted to International Conference on Learning Representations (ICLR).
- *2026.1*: Our paper about *Don't Forget Its Variance! The Minimum Path Variance Principle for Accurate and Stable Score-Based Density Ratio* is accepted to  International Conference on Learning Representations (ICLR).
- *2025.10*: Our paper about *diffusion informer for time series modeling* is accepted to Expert Systems With Applications (ESWA).
- *2025.10*: Our paper about *wavelet diffusion for time series modeling* is accepted to IEEE TIM.
- *2025.09*: Our paper about *diffusion modeling acceleration* is accepted to NeurIPS 2025.
- *2025.09*: Our paper about *normalizing flow* is accepted to Pattern Recognition (PR).
- *2025.08*: Our paper about *diffusion models for low-level CV* is accepted to Neurocomputing.
- *2025.10*: Our paper about *time series modeling* is accepted to IEEE Transactions on Instrumentation & Measurement (TIM).
- *2025.05*: Our paper about *stable & efficient density ratio estimation* is accepted to ICML 2025.
- *2024.06*: Our paper about *Sparse Inducing Points in Deep Gaussian Processes: Enhancing Modeling with Denoising Diffusion Variational Inference* is accepted to ICML 2024. 
- *2022.02*: Our paper about *efficient continuous normalizing flow* is accepted to CVPR 2022. 

# ğŸ“ Publications 
## Deep Generative Modeling

<div class='paper-box'><div class='paper-box-image'><img src='images/evodiff.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**EVODiff: Entropy-aware Variance Optimized Diffusion Inference**](https://openreview.net/forum?id=rKASv92Myl), Shigui Li, **`Wei Chen`**, Delu Zeng*

**NeurIPS 2025** \| [**Paper**](https://openreview.net/pdf?id=rKASv92Myl) \| [**Code**](https://github.com/ShiguiLi/EVODiff) \| [**News&#127881;**](https://mp.weixin.qq.com/s/mviiMgexMub_os4oSIdwiQ)

- Introduces an information-theoretic view: successful denoising reduces conditional entropy in reverse transitions.
- Proposes EVODiff, a reference-free diffusion inference framework that optimizes conditional variance to reduce transition and reconstruction errors, improving sample quality and reducing inference cost.
</div>
</div>



# ğŸ– Honors and Awards


# ğŸ“– Educations
 

# ğŸ’¬ Invited Talks


# ğŸ’» Internships
  - 
